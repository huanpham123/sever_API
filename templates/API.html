<!DOCTYPE html>
<html lang="vi">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice Chat AI</title>
    <style>
        body { font-family: Arial, sans-serif; max-width: 600px; margin: 0 auto; padding: 20px; }
        button { padding: 10px 15px; margin: 5px; font-size: 16px; cursor: pointer; }
        #status { margin: 15px 0; color: #666; }
        #responseAudio { width: 100%; margin-top: 20px; }
    </style>
</head>
<body>
    <h1>Voice Chat v·ªõi AI</h1>
    <button id="startBtn">üé§ B·∫Øt ƒë·∫ßu thu √¢m</button>
    <button id="stopBtn" disabled>‚èπ D·ª´ng v√† g·ª≠i</button>
    <p id="status">Nh·∫•n n√∫t ƒë·ªÉ b·∫Øt ƒë·∫ßu thu √¢m...</p>
    <audio id="responseAudio" controls></audio>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/RecordRTC/5.6.2/RecordRTC.min.js"></script>
    <script>
        let recorder;
        let audioStream;
        const startBtn = document.getElementById('startBtn');
        const stopBtn = document.getElementById('stopBtn');
        const statusEl = document.getElementById('status');
        const audioEl = document.getElementById('responseAudio');

        startBtn.onclick = async () => {
            try {
                statusEl.textContent = 'ƒêang y√™u c·∫ßu quy·ªÅn mic...';
                audioStream = await navigator.mediaDevices.getUserMedia({ audio: true });
                
                statusEl.textContent = 'ƒêang thu √¢m...';
                startBtn.disabled = true;
                stopBtn.disabled = false;
                
                recorder = new RecordRTC(audioStream, {
                    type: 'audio',
                    mimeType: 'audio/webm',
                    sampleRate: 16000,
                    numberOfAudioChannels: 1
                });
                
                recorder.startRecording();
            } catch (err) {
                statusEl.textContent = 'L·ªói: ' + err.message;
                console.error(err);
                startBtn.disabled = false;
            }
        };

        stopBtn.onclick = async () => {
            try {
                statusEl.textContent = 'ƒêang x·ª≠ l√Ω...';
                stopBtn.disabled = true;
                
                await new Promise(resolve => {
                    recorder.stopRecording(resolve);
                });
                
                // D·ª´ng c√°c track audio
                audioStream.getTracks().forEach(track => track.stop());
                
                const blob = recorder.getBlob();
                const formData = new FormData();
                formData.append('audio', blob, 'recording.webm');
                
                const response = await fetch('/process', {
                    method: 'POST',
                    body: formData
                });
                
                if (!response.ok) {
                    throw new Error(await response.text());
                }
                
                const audioBlob = await response.blob();
                audioEl.src = URL.createObjectURL(audioBlob);
                audioEl.play();
                
                statusEl.textContent = 'Ho√†n th√†nh! Nh·∫•n ƒë·ªÉ thu √¢m l·∫°i';
            } catch (err) {
                statusEl.textContent = 'L·ªói: ' + err.message;
                console.error(err);
            } finally {
                startBtn.disabled = false;
            }
        };
    </script>
</body>
</html>
